{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Sort & Rename images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def natural_sort_key(s):\n",
    "    # Extract numbers and return as a sorting key\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def list_image_files(directory):\n",
    "    # List to store image file names\n",
    "    image_files = []\n",
    "\n",
    "    # Walk through directory and subdirectories\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            image_files.append(os.path.join(file))\n",
    "            \n",
    "    image_files.sort(key=natural_sort_key)\n",
    "    return image_files\n",
    "\n",
    "def rename_files(directory):\n",
    "    day = input(\"day: \")\n",
    "    temp = input(\"temp: \")\n",
    "    rep = 1\n",
    "    pic = 1\n",
    "    \n",
    "    # Get the sorted list of image files\n",
    "    image_files = list_image_files(directory)\n",
    "    \n",
    "    for file in image_files:\n",
    "        print(file)\n",
    "        if pic == 3:\n",
    "            pic = 1\n",
    "            rep += 1\n",
    "        os.rename(directory + \"/\" + file, directory+ \"/\" + f\"a_{day}_{temp}_{str(rep)}_{str(pic)}\" + '.jpg')\n",
    "        pic += 1\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"../raw_images/Day 8_24 Jan 2023/15C\"\n",
    "rename_files(directory_path)\n",
    "# image_files = list_image_files(directory_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Image Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image = cv2.imread('../raw_images/0_5_1_1.JPG')\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB for visualization\n",
    "plt.imshow(image_rgb)\n",
    "plt.title(\"Original Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Normalize the pixel values to range [0, 1]\n",
    "normalized_image = gray_image / 255.0\n",
    "\n",
    "plt.imshow(normalized_image, cmap='gray')\n",
    "plt.title(\"Preprocessed Image\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Mask Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding to create a binary mask\n",
    "_, binary_mask = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Morphological operations to clean up the mask\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "cleaned_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "plt.imshow(cleaned_mask, cmap='gray')\n",
    "plt.title(\"Binary Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the leaf area using the mask\n",
    "leaf_area = cv2.bitwise_and(image, image, mask=cleaned_mask)\n",
    "\n",
    "plt.imshow(leaf_area)\n",
    "plt.title(\"Leaf Area\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the target area for better focus\n",
    "leaf_area_normalized = leaf_area / 255.0\n",
    "\n",
    "plt.imshow(leaf_area_normalized)\n",
    "plt.title(\"Normalized Leaf Area\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Convert to HSV color space\n",
    "image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define green color range (adjust based on your image)\n",
    "lower_green = np.array([30, 40, 40])  # Hue, Saturation, Value\n",
    "upper_green = np.array([90, 255, 255])\n",
    "\n",
    "# Create a mask for green regions\n",
    "mask_green = cv2.inRange(image_hsv, lower_green, upper_green)\n",
    "\n",
    "# Apply the mask to the original image\n",
    "green_area = cv2.bitwise_and(image_rgb, image_rgb, mask=mask_green)\n",
    "\n",
    "plt.imshow(green_area)\n",
    "plt.title(\"Green Area (HSV Segmentation)\")\n",
    "plt.show()\n",
    "cv2.imwrite(\"hsv_green_area.jpg\", cv2.cvtColor(green_area, cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to grayscale for edge detection\n",
    "gray_image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Apply GaussianBlur to reduce noise\n",
    "blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "edges = cv2.Canny(blurred_image, threshold1=50, threshold2=150)\n",
    "\n",
    "plt.imshow(edges, cmap='gray')\n",
    "plt.title(\"Edge Detection (Canny)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Function to segment and extract leaves using Mask R-CNN\n",
    "def extract_leaves_with_maskrcnn(image_path, output_path, threshold=0.5):\n",
    "    # Load pretrained Mask R-CNN model\n",
    "    model = maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    model.eval()\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_tensor = F.to_tensor(image).unsqueeze(0)\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        predictions = model(image_tensor)\n",
    "\n",
    "    # Extract masks, scores, and labels\n",
    "    masks = predictions[0]['masks'].squeeze().cpu().numpy()\n",
    "    scores = predictions[0]['scores'].cpu().numpy()\n",
    "    labels = predictions[0]['labels'].cpu().numpy()\n",
    "\n",
    "    # Combine masks for objects with high confidence\n",
    "    final_mask = np.zeros_like(masks[0], dtype=np.uint8)\n",
    "    for i in range(len(scores)):\n",
    "        if scores[i] >= threshold and labels[i] == 15:  # Class '15' = person; replace for custom class\n",
    "            final_mask = np.maximum(final_mask, (masks[i] > 0.5).astype(np.uint8))\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    image_np = np.array(image)\n",
    "    result = image_np * np.expand_dims(final_mask, axis=2)\n",
    "\n",
    "    # Save the result\n",
    "    result_image = Image.fromarray(result.astype('uint8'))\n",
    "    result_image.save(output_path)\n",
    "    print(f\"Extracted leaf saved to {output_path}\")\n",
    "\n",
    "# Process a folder of images\n",
    "def process_folder_with_maskrcnn(input_folder, output_folder, threshold=0.5):\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, f\"extracted_{filename}\")\n",
    "            extract_leaves_with_maskrcnn(input_path, output_path, threshold)\n",
    "# Example usage\n",
    "input_folder = \"../raw_images\"  # Replace with your folder path\n",
    "output_folder = \"../output/r_cnn\"  # Replace with your desired output folder path\n",
    "\n",
    "process_folder_with_maskrcnn(input_folder, output_folder, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import functional as F\n",
    "import torch\n",
    "\n",
    "# Load your dataset\n",
    "class CustomDataset(CocoDetection):\n",
    "    def __init__(self, img_folder, ann_file, transforms=None):\n",
    "        super(CustomDataset, self).__init__(img_folder, ann_file)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, target = super(CustomDataset, self).__getitem__(idx)\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        return img, target\n",
    "\n",
    "# Define the training function\n",
    "def train_model(dataset_path, annotation_path, model_save_path):\n",
    "    # Load dataset\n",
    "    dataset = CustomDataset(\n",
    "        img_folder=dataset_path,\n",
    "        ann_file=annotation_path,\n",
    "        transforms=F.to_tensor\n",
    "    )\n",
    "    dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "    # Load Mask R-CNN model\n",
    "    model = maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    num_classes = 2  # Background and leaf\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    # Train the model\n",
    "    model.train()\n",
    "    for epoch in range(10):  # Number of epochs\n",
    "        for imgs, targets in dataloader:\n",
    "            imgs = [img for img in imgs]\n",
    "            loss_dict = model(imgs, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            print(f\"Epoch {epoch}, Loss: {losses.item()}\")\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model, model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "# Train the model\n",
    "train_model(\n",
    "    dataset_path=\"/path/to/your/images\",\n",
    "    annotation_path=\"/path/to/your/annotations.json\",\n",
    "    model_save_path=\"/path/to/save/model.pth\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gray Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def extract_leaves_white_bg(image_path, output_path):\n",
    "      # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    original = image.copy()\n",
    "\n",
    "    # Convert the image to grayscale and HSV\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Apply adaptive thresholding for general segmentation\n",
    "    adaptive_mask = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # Define color ranges for green and yellow leaves\n",
    "    lower_green = np.array([25, 40, 40])  # Green color range\n",
    "    upper_green = np.array([90, 255, 255])\n",
    "\n",
    "    lower_yellow = np.array([20, 100, 100])  # Yellow color range\n",
    "    upper_yellow = np.array([40, 255, 255])\n",
    "\n",
    "    # Create color masks\n",
    "    green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "\n",
    "    # Combine color masks\n",
    "    color_mask = cv2.bitwise_or(green_mask, yellow_mask)\n",
    "\n",
    "    # Combine with adaptive thresholding mask\n",
    "    combined_mask = cv2.bitwise_and(color_mask, adaptive_mask)\n",
    "\n",
    "    # Refine mask with morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    refined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    refined_mask = cv2.morphologyEx(refined_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Extract the leaves by applying the refined mask\n",
    "    result = cv2.bitwise_and(original, original, mask=refined_mask)\n",
    "\n",
    "    # Save the result\n",
    "    cv2.imwrite(output_path, result)\n",
    "    print(f\"Processed and saved: {output_path}\")\n",
    "\n",
    "# Process a folder of images\n",
    "def process_folder_white_bg(input_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, f\"{filename}\")\n",
    "            extract_leaves_white_bg(input_path, output_path)\n",
    "\n",
    "# Example usage\n",
    "input_folder = \"../raw_images\"  # Replace with your folder containing input images\n",
    "output_folder = \"../output/gray_extract\"  # Replace with the desired output folder\n",
    "\n",
    "process_folder_white_bg(input_folder, output_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def extract_leaves_with_gaussian(image_path, output_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    original = image.copy()\n",
    "\n",
    "    # Convert the image to grayscale and HSV\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Apply Gaussian blur to smooth the image\n",
    "    blurred = cv2.GaussianBlur(gray, (9, 9), 0)\n",
    "\n",
    "    # Apply adaptive thresholding for general segmentation\n",
    "    adaptive_mask = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # Define color ranges for green and yellow leaves\n",
    "    lower_green = np.array([25, 40, 40])  # Green color range\n",
    "    upper_green = np.array([90, 255, 255])\n",
    "\n",
    "    lower_yellow = np.array([20, 100, 100])  # Yellow color range\n",
    "    upper_yellow = np.array([40, 255, 255])\n",
    "\n",
    "    # Create color masks\n",
    "    green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "\n",
    "    # Combine color masks\n",
    "    color_mask = cv2.bitwise_or(green_mask, yellow_mask)\n",
    "\n",
    "    # Combine with adaptive thresholding mask\n",
    "    combined_mask = cv2.bitwise_and(color_mask, adaptive_mask)\n",
    "\n",
    "    # Apply Gaussian blur to refine the combined mask\n",
    "    refined_mask = cv2.GaussianBlur(combined_mask, (5, 5), 0)\n",
    "\n",
    "    # Further refine with morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    refined_mask = cv2.morphologyEx(refined_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    refined_mask = cv2.morphologyEx(refined_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Extract the leaves by applying the refined mask\n",
    "    result = cv2.bitwise_and(original, original, mask=refined_mask)\n",
    "\n",
    "    # Save the result\n",
    "    cv2.imwrite(output_path, result)\n",
    "    print(f\"Processed and saved: {output_path}\")\n",
    "\n",
    "# Process a folder of images\n",
    "def process_folder_with_gaussian(input_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, f\"extracted_{filename}\")\n",
    "            extract_leaves_with_gaussian(input_path, output_path)\n",
    "\n",
    "# Example usage\n",
    "input_folder = \"../raw_images\"  # Replace with your folder containing input images\n",
    "output_folder = \"../output/gassian\"  # Replace with the desired output folder\n",
    "\n",
    "process_folder_with_gaussian(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configure logging for the main process\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler()],\n",
    "    force=True\n",
    ")\n",
    "\n",
    "# Function to configure logging in each process\n",
    "def setup_logging():\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[logging.StreamHandler()]\n",
    "    )\n",
    "\n",
    "# Function to process a single image\n",
    "def process_image(args):\n",
    "    input_path, output_path = args\n",
    "    setup_logging()  # Ensure logging is set up for this child process\n",
    "    try:\n",
    "        logging.info(f\"Processing image: {input_path}\")\n",
    "\n",
    "        # Load the image\n",
    "        image = cv2.imread(input_path)\n",
    "        if image is None:\n",
    "            logging.error(f\"Failed to load image: {input_path}\")\n",
    "            return\n",
    "\n",
    "        logging.info(\"Image loaded successfully.\")\n",
    "\n",
    "        # Step 1: Resize the image to speed up processing (scale to 50%)\n",
    "        height, width = image.shape[:2]\n",
    "        scale_factor = 0.5\n",
    "        image_resized = cv2.resize(image, (int(width * scale_factor), int(height * scale_factor)))\n",
    "        logging.info(f\"Image resized to {image_resized.shape[:2]} for faster processing.\")\n",
    "\n",
    "        # Step 2: Define the rectangle for GrabCut (tight bounding box)\n",
    "        resized_height, resized_width = image_resized.shape[:2]\n",
    "        rect = (10, 10, resized_width - 20, resized_height - 20)\n",
    "        logging.info(f\"Defined rectangle for GrabCut: {rect}\")\n",
    "\n",
    "        # Step 3: Initialize GrabCut mask and models\n",
    "        mask = np.zeros(image_resized.shape[:2], np.uint8)\n",
    "        bgd_model = np.zeros((1, 65), np.float64)\n",
    "        fgd_model = np.zeros((1, 65), np.float64)\n",
    "        logging.info(\"Initialized GrabCut models.\")\n",
    "\n",
    "        # Step 4: Run GrabCut with fewer iterations\n",
    "        logging.info(\"Starting GrabCut process...\")\n",
    "        cv2.grabCut(image_resized, mask, rect, bgd_model, fgd_model, 2, cv2.GC_INIT_WITH_RECT)\n",
    "        logging.info(\"GrabCut process completed.\")\n",
    "\n",
    "        # Step 5: Convert GrabCut mask to binary format\n",
    "        mask_binary = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "        logging.info(\"Converted mask to binary format.\")\n",
    "\n",
    "        # Step 6: Extract the foreground (leaves) from the resized image\n",
    "        foreground = image_resized * mask_binary[:, :, np.newaxis]\n",
    "\n",
    "        # Step 7: Resize back to the original resolution\n",
    "        result = cv2.resize(foreground, (width, height))\n",
    "        logging.info(\"Resized result back to original dimensions.\")\n",
    "\n",
    "        # Save the result\n",
    "        cv2.imwrite(output_path, result)\n",
    "        logging.info(f\"Processed image saved to: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing image {input_path}: {str(e)}\")\n",
    "\n",
    "# Function to process a folder of images\n",
    "def process_folder_grabcut(input_folder, output_folder):\n",
    "    try:\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "            logging.info(f\"Created output folder: {output_folder}\")\n",
    "\n",
    "        # Get all image files\n",
    "        image_files = [\n",
    "            (os.path.join(input_folder, f), os.path.join(output_folder, f\"grabcut_{f}\"))\n",
    "            for f in os.listdir(input_folder)\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "        ]\n",
    "\n",
    "        # Use multiprocessing for parallel processing\n",
    "        with Pool() as pool:  # Adjust the number of processes based on your CPU cores\n",
    "            pool.map(process_image, image_files)\n",
    "\n",
    "        logging.info(\"All images processed successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing folder: {str(e)}\")\n",
    "\n",
    "# Example usage\n",
    "input_folder = \"../raw_images\" \n",
    "output_folder = \"../output/grapcut\"\n",
    "\n",
    "process_folder_grabcut(input_folder, output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kale_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
