{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Load data | Day_Treatment_Rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>R_Mean</th>\n",
       "      <th>R_Std</th>\n",
       "      <th>G_Mean</th>\n",
       "      <th>G_Std</th>\n",
       "      <th>B_Mean</th>\n",
       "      <th>B_Std</th>\n",
       "      <th>H_Mean</th>\n",
       "      <th>H_Std</th>\n",
       "      <th>S_Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>V_Mean</th>\n",
       "      <th>V_Std</th>\n",
       "      <th>L_Mean</th>\n",
       "      <th>L_Std</th>\n",
       "      <th>a_Mean</th>\n",
       "      <th>a_Std</th>\n",
       "      <th>b_Mean</th>\n",
       "      <th>b_Std</th>\n",
       "      <th>Day</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158.9</td>\n",
       "      <td>202.031017</td>\n",
       "      <td>63.184791</td>\n",
       "      <td>206.361271</td>\n",
       "      <td>55.761869</td>\n",
       "      <td>195.552566</td>\n",
       "      <td>74.087194</td>\n",
       "      <td>48.603222</td>\n",
       "      <td>56.316379</td>\n",
       "      <td>26.942528</td>\n",
       "      <td>...</td>\n",
       "      <td>207.003862</td>\n",
       "      <td>55.870933</td>\n",
       "      <td>208.442289</td>\n",
       "      <td>55.784846</td>\n",
       "      <td>124.388767</td>\n",
       "      <td>7.205789</td>\n",
       "      <td>133.458801</td>\n",
       "      <td>10.995181</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154.5</td>\n",
       "      <td>196.388049</td>\n",
       "      <td>57.669474</td>\n",
       "      <td>200.363846</td>\n",
       "      <td>50.615080</td>\n",
       "      <td>189.855627</td>\n",
       "      <td>68.516092</td>\n",
       "      <td>63.280031</td>\n",
       "      <td>57.690568</td>\n",
       "      <td>26.164496</td>\n",
       "      <td>...</td>\n",
       "      <td>201.372722</td>\n",
       "      <td>50.922278</td>\n",
       "      <td>203.303091</td>\n",
       "      <td>50.910815</td>\n",
       "      <td>124.570902</td>\n",
       "      <td>7.112593</td>\n",
       "      <td>133.317630</td>\n",
       "      <td>10.926267</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149.7</td>\n",
       "      <td>196.586956</td>\n",
       "      <td>56.816229</td>\n",
       "      <td>200.405571</td>\n",
       "      <td>50.129378</td>\n",
       "      <td>190.606173</td>\n",
       "      <td>67.044048</td>\n",
       "      <td>63.870066</td>\n",
       "      <td>57.068227</td>\n",
       "      <td>24.570594</td>\n",
       "      <td>...</td>\n",
       "      <td>201.448391</td>\n",
       "      <td>50.424279</td>\n",
       "      <td>203.433086</td>\n",
       "      <td>50.298129</td>\n",
       "      <td>124.747403</td>\n",
       "      <td>6.862492</td>\n",
       "      <td>132.948486</td>\n",
       "      <td>10.475270</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148.4</td>\n",
       "      <td>206.840822</td>\n",
       "      <td>58.391917</td>\n",
       "      <td>210.816657</td>\n",
       "      <td>51.437818</td>\n",
       "      <td>201.517561</td>\n",
       "      <td>68.725207</td>\n",
       "      <td>52.674892</td>\n",
       "      <td>54.528216</td>\n",
       "      <td>22.998771</td>\n",
       "      <td>...</td>\n",
       "      <td>211.541725</td>\n",
       "      <td>51.588476</td>\n",
       "      <td>212.927224</td>\n",
       "      <td>51.478033</td>\n",
       "      <td>124.804936</td>\n",
       "      <td>6.758229</td>\n",
       "      <td>132.644228</td>\n",
       "      <td>10.385137</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147.5</td>\n",
       "      <td>207.421014</td>\n",
       "      <td>58.118789</td>\n",
       "      <td>211.122241</td>\n",
       "      <td>51.420555</td>\n",
       "      <td>202.135509</td>\n",
       "      <td>68.412750</td>\n",
       "      <td>53.727779</td>\n",
       "      <td>56.380803</td>\n",
       "      <td>22.434080</td>\n",
       "      <td>...</td>\n",
       "      <td>211.884094</td>\n",
       "      <td>51.545167</td>\n",
       "      <td>213.275613</td>\n",
       "      <td>51.336971</td>\n",
       "      <td>124.952920</td>\n",
       "      <td>6.614468</td>\n",
       "      <td>132.517304</td>\n",
       "      <td>10.255598</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight      R_Mean      R_Std      G_Mean      G_Std      B_Mean  \\\n",
       "0   158.9  202.031017  63.184791  206.361271  55.761869  195.552566   \n",
       "1   154.5  196.388049  57.669474  200.363846  50.615080  189.855627   \n",
       "2   149.7  196.586956  56.816229  200.405571  50.129378  190.606173   \n",
       "3   148.4  206.840822  58.391917  210.816657  51.437818  201.517561   \n",
       "4   147.5  207.421014  58.118789  211.122241  51.420555  202.135509   \n",
       "\n",
       "       B_Std     H_Mean      H_Std     S_Mean  ...      V_Mean      V_Std  \\\n",
       "0  74.087194  48.603222  56.316379  26.942528  ...  207.003862  55.870933   \n",
       "1  68.516092  63.280031  57.690568  26.164496  ...  201.372722  50.922278   \n",
       "2  67.044048  63.870066  57.068227  24.570594  ...  201.448391  50.424279   \n",
       "3  68.725207  52.674892  54.528216  22.998771  ...  211.541725  51.588476   \n",
       "4  68.412750  53.727779  56.380803  22.434080  ...  211.884094  51.545167   \n",
       "\n",
       "       L_Mean      L_Std      a_Mean     a_Std      b_Mean      b_Std  Day  \\\n",
       "0  208.442289  55.784846  124.388767  7.205789  133.458801  10.995181    0   \n",
       "1  203.303091  50.910815  124.570902  7.112593  133.317630  10.926267    1   \n",
       "2  203.433086  50.298129  124.747403  6.862492  132.948486  10.475270    2   \n",
       "3  212.927224  51.478033  124.804936  6.758229  132.644228  10.385137    3   \n",
       "4  213.275613  51.336971  124.952920  6.614468  132.517304  10.255598    4   \n",
       "\n",
       "  Temp  \n",
       "0    5  \n",
       "1    5  \n",
       "2    5  \n",
       "3    5  \n",
       "4    5  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../materials/process_csv/weight_color_data.csv')\n",
    "df['Day'] = df['Label'].apply(lambda x: x.split('_')[0])\n",
    "df['Temp'] = df['Label'].apply(lambda x: x.split('_')[1])\n",
    "df.drop('Label', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Weight', 'R_Mean', 'R_Std', 'G_Mean', 'G_Std', 'B_Mean', 'B_Std',\n",
       "       'H_Mean', 'H_Std', 'S_Mean', 'S_Std', 'V_Mean', 'V_Std', 'L_Mean',\n",
       "       'L_Std', 'a_Mean', 'a_Std', 'b_Mean', 'b_Std', 'Day', 'Temp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, HuberRegressor, QuantileRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_features = {\n",
    "    \"L\": [\"L_Mean\", \"L_Std\"],\n",
    "    \"a\": [\"a_Mean\", \"a_Std\"],\n",
    "    \"b\": [\"b_Mean\", \"b_Std\"],\n",
    "    \"H\": [\"H_Mean\", \"H_Std\"],\n",
    "    \"S\": [\"S_Mean\", \"S_Std\"],\n",
    "    \"V\": [\"V_Mean\", \"V_Std\"],\n",
    "    \"R\": [\"R_Mean\", \"R_Std\"],\n",
    "    \"G\": [\"G_Mean\", \"G_Std\"],\n",
    "    \"B\": [\"B_Mean\", \"B_Std\"],\n",
    "    # \"Day\": [\"Day\"],\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(alpha=1.0),\n",
    "    \"Lasso Regression\": Lasso(alpha=0.1),\n",
    "    \"Polynomial Regression\": make_pipeline(PolynomialFeatures(degree=2), LinearRegression()),\n",
    "    \"Elastic Net\": ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
    "    \"Huber Regressor\": HuberRegressor(),\n",
    "    \"Quantile Regressor\": QuantileRegressor(quantile=0.5, alpha=0.1),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressive_features(features_dict):\n",
    "    feature_combinations = {}\n",
    "\n",
    "    feature_groups = list(features_dict.keys())  # [\"L\", \"a\", \"b\", \"H\", ...]\n",
    "    \n",
    "    for i in range(1, len(feature_groups) + 1):\n",
    "        for comb in combinations(feature_groups, i):  # Create feature group combinations\n",
    "            combined_columns = sum([features_dict[key] for key in comb], [])  # Map to actual column names\n",
    "            feature_combinations[\",\".join(comb)] = combined_columns\n",
    "\n",
    "    print(f\"Generated {len(feature_combinations)} feature combinations.\")\n",
    "    return feature_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_orange(df, red_weight=0.8, green_weight=0.2):\n",
    "    \"\"\"\n",
    "    Create a new feature that represents a mixed color (Orange) from Red and Green.\n",
    "    \n",
    "    This function computes both:\n",
    "    - Mixed color (Mean values)\n",
    "    - Mixed color (Standard Deviation)\n",
    "    - Converts the mixed color to LAB and HSV\n",
    "    \"\"\"\n",
    "    # Compute the mixed color mean\n",
    "    df[\"Mixed_RedGreen_Mean\"] = (df[\"R_Mean\"] * red_weight + df[\"G_Mean\"] * green_weight).astype(int)\n",
    "\n",
    "    # Compute the mixed color standard deviation\n",
    "    df[\"Mixed_RedGreen_Std\"] = (df[\"R_Std\"] * red_weight + df[\"G_Std\"] * green_weight).astype(int)\n",
    "\n",
    "    # Convert Mixed RGB to LAB & HSV\n",
    "    mixed_rgb = np.stack([df[\"Mixed_RedGreen_Mean\"], df[\"Mixed_RedGreen_Mean\"], np.zeros_like(df[\"Mixed_RedGreen_Mean\"])], axis=1)\n",
    "    mixed_bgr = np.array(mixed_rgb, dtype=np.uint8)[:, np.newaxis, :]  # Convert to BGR format\n",
    "    \n",
    "    mixed_lab = cv2.cvtColor(mixed_bgr, cv2.COLOR_RGB2LAB)[:, 0, :]\n",
    "    mixed_hsv = cv2.cvtColor(mixed_bgr, cv2.COLOR_RGB2HSV)[:, 0, :]\n",
    "\n",
    "    # Add Mean Values\n",
    "    df[\"Mixed_L_Mean\"] = mixed_lab[:, 0]\n",
    "    df[\"Mixed_a_Mean\"] = mixed_lab[:, 1]\n",
    "    df[\"Mixed_b_Mean\"] = mixed_lab[:, 2]\n",
    "\n",
    "    df[\"Mixed_H_Mean\"] = mixed_hsv[:, 0]\n",
    "    df[\"Mixed_S_Mean\"] = mixed_hsv[:, 1]\n",
    "    df[\"Mixed_V_Mean\"] = mixed_hsv[:, 2]\n",
    "\n",
    "    # Add Standard Deviation (Since we're mixing, we use an estimated std based on weighted input stds)\n",
    "    df[\"Mixed_L_Std\"] = (df[\"L_Std\"] * red_weight + df[\"L_Std\"] * green_weight).astype(int)\n",
    "    df[\"Mixed_a_Std\"] = (df[\"a_Std\"] * red_weight + df[\"a_Std\"] * green_weight).astype(int)\n",
    "    df[\"Mixed_b_Std\"] = (df[\"b_Std\"] * red_weight + df[\"b_Std\"] * green_weight).astype(int)\n",
    "\n",
    "    df[\"Mixed_H_Std\"] = (df[\"H_Std\"] * red_weight + df[\"H_Std\"] * green_weight).astype(int)\n",
    "    df[\"Mixed_S_Std\"] = (df[\"S_Std\"] * red_weight + df[\"S_Std\"] * green_weight).astype(int)\n",
    "    df[\"Mixed_V_Std\"] = (df[\"V_Std\"] * red_weight + df[\"V_Std\"] * green_weight).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "base_features[\"Orange\"] = [\"Mixed_RedGreen_Mean\", \"Mixed_RedGreen_Std\"]\n",
    "base_features[\"Orange_Lab\"] = [\"Mixed_L_Mean\", \"Mixed_a_Mean\", \"Mixed_b_Mean\", \"Mixed_L_Std\", \"Mixed_a_Std\", \"Mixed_b_Std\"]\n",
    "base_features[\"Orange_HSV\"] = [\"Mixed_H_Mean\", \"Mixed_S_Mean\", \"Mixed_V_Mean\", \"Mixed_H_Std\", \"Mixed_S_Std\", \"Mixed_V_Std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_yellow(df, red_weight=0.5, green_weight=0.5):\n",
    "    \"\"\"\n",
    "    Create a new feature that represents a mixed color (Yellow) from Red and Green.\n",
    "    \n",
    "    This function computes:\n",
    "    - Mixed color (Mean values)\n",
    "    - Mixed color (Standard Deviation)\n",
    "    - Converts the mixed color to LAB and HSV\n",
    "    \"\"\"\n",
    "    # Compute the mixed color mean\n",
    "    df[\"Mixed_RedGreenYellow_Mean\"] = (df[\"R_Mean\"] * red_weight + df[\"G_Mean\"] * green_weight).astype(int)\n",
    "\n",
    "    # Compute the mixed color standard deviation\n",
    "    df[\"Mixed_RedGreenYellow_Std\"] = (df[\"R_Std\"] * red_weight + df[\"G_Std\"] * green_weight).astype(int)\n",
    "\n",
    "    # Convert Mixed RGB to LAB & HSV\n",
    "    mixed_rgb = np.stack([df[\"Mixed_RedGreenYellow_Mean\"], df[\"Mixed_RedGreenYellow_Mean\"], np.zeros_like(df[\"Mixed_RedGreenYellow_Mean\"])], axis=1)\n",
    "    mixed_bgr = np.array(mixed_rgb, dtype=np.uint8)[:, np.newaxis, :]  # Convert to BGR format\n",
    "    \n",
    "    mixed_lab = cv2.cvtColor(mixed_bgr, cv2.COLOR_RGB2LAB)[:, 0, :]\n",
    "    mixed_hsv = cv2.cvtColor(mixed_bgr, cv2.COLOR_RGB2HSV)[:, 0, :]\n",
    "\n",
    "    # Add Mean Values\n",
    "    df[\"Mixed_Yellow_L_Mean\"] = mixed_lab[:, 0]\n",
    "    df[\"Mixed_Yellow_a_Mean\"] = mixed_lab[:, 1]\n",
    "    df[\"Mixed_Yellow_b_Mean\"] = mixed_lab[:, 2]\n",
    "\n",
    "    df[\"Mixed_Yellow_H_Mean\"] = mixed_hsv[:, 0]\n",
    "    df[\"Mixed_Yellow_S_Mean\"] = mixed_hsv[:, 1]\n",
    "    df[\"Mixed_Yellow_V_Mean\"] = mixed_hsv[:, 2]\n",
    "\n",
    "    # Add Standard Deviation (Since we're mixing, we use an estimated std based on weighted input stds)\n",
    "    df[\"Mixed_Yellow_L_Std\"] = (df[\"L_Std\"] * red_weight + df[\"L_Std\"] * green_weight).astype(int)\n",
    "    df[\"Mixed_Yellow_a_Std\"] = (df[\"a_Std\"] * red_weight + df[\"a_Std\"] * green_weight).astype(int)\n",
    "    df[\"Mixed_Yellow_b_Std\"] = (df[\"b_Std\"] * red_weight + df[\"b_Std\"] * green_weight).astype(int)\n",
    "\n",
    "    df[\"Mixed_Yellow_H_Std\"] = (df[\"H_Std\"] * red_weight + df[\"H_Std\"] * green_weight).astype(int)\n",
    "    df[\"Mixed_Yellow_S_Std\"] = (df[\"S_Std\"] * red_weight + df[\"S_Std\"] * green_weight).astype(int)\n",
    "    df[\"Mixed_Yellow_V_Std\"] = (df[\"V_Std\"] * red_weight + df[\"V_Std\"] * green_weight).astype(int)\n",
    "\n",
    "    return df\n",
    "base_features[\"Yellow\"] = [\"Mixed_RedGreenYellow_Mean\", \"Mixed_RedGreenYellow_Std\"]\n",
    "base_features[\"Yellow_LAB\"] = [\"Mixed_Yellow_L_Mean\", \"Mixed_Yellow_a_Mean\", \"Mixed_Yellow_b_Mean\", \"Mixed_Yellow_L_Std\", \"Mixed_Yellow_a_Std\", \"Mixed_Yellow_b_Std\"]\n",
    "base_features[\"Yellow_HSV\"] = [\"Mixed_Yellow_H_Mean\", \"Mixed_Yellow_S_Mean\", \"Mixed_Yellow_V_Mean\", \"Mixed_Yellow_H_Std\", \"Mixed_Yellow_S_Std\", \"Mixed_Yellow_V_Std\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interaction_features(df):\n",
    "    \"\"\"\n",
    "    Creates interaction features (cross-multiplication) to enhance model learning.\n",
    "    \"\"\"\n",
    "    df[\"R_G_Interaction\"] = df[\"R_Mean\"] * df[\"G_Mean\"]\n",
    "    df[\"R_B_Interaction\"] = df[\"R_Mean\"] * df[\"B_Mean\"]\n",
    "    df[\"G_B_Interaction\"] = df[\"G_Mean\"] * df[\"B_Mean\"]\n",
    "    \n",
    "    df[\"L_H_Interaction\"] = df[\"L_Mean\"] * df[\"H_Mean\"]\n",
    "    df[\"a_S_Interaction\"] = df[\"a_Mean\"] * df[\"S_Mean\"]\n",
    "    df[\"b_V_Interaction\"] = df[\"b_Mean\"] * df[\"V_Mean\"]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_polynomial_features(X, degree=2):\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    return pd.DataFrame(X_poly, columns=poly.get_feature_names_out(X.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ Train and Evaluate Models\n",
    "def train_and_evaluate(X, y, feature_sets, models, output_csv_path):\n",
    "    results = []\n",
    "\n",
    "    # Split dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # âœ… Scale Data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Convert back to DataFrame\n",
    "    X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "    X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "    for feature_name, feature_list in feature_sets.items():\n",
    "        X_train_subset = X_train[feature_list]\n",
    "        X_test_subset = X_test[feature_list]\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            model.fit(X_train_subset, y_train)\n",
    "            y_pred = model.predict(X_test_subset)\n",
    "\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            # Store results\n",
    "            results.append({\n",
    "                \"Feature Set\": feature_name,\n",
    "                \"Model\": model_name,\n",
    "                \"MSE\": mse,\n",
    "                \"R2 Score\": r2\n",
    "            })\n",
    "\n",
    "            logging.info(f\"Features: {feature_name}, Model: {model_name}, MSE: {mse:.4f}, R2 Score: {r2:.4f}\")\n",
    "\n",
    "    # Save results\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Regression evaluation complete. Results saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Mixed_RedGreen_Mean', 'Mixed_RedGreen_Std', 'Mixed_L_Mean', 'Mixed_a_Mean', 'Mixed_b_Mean', 'Mixed_L_Std', 'Mixed_a_Std', 'Mixed_b_Std', 'Mixed_H_Mean', 'Mixed_S_Mean', 'Mixed_V_Mean', 'Mixed_H_Std', 'Mixed_S_Std', 'Mixed_V_Std', 'Mixed_RedGreenYellow_Mean', 'Mixed_RedGreenYellow_Std', 'Mixed_Yellow_L_Mean', 'Mixed_Yellow_a_Mean', 'Mixed_Yellow_b_Mean', 'Mixed_Yellow_L_Std', 'Mixed_Yellow_a_Std', 'Mixed_Yellow_b_Std', 'Mixed_Yellow_H_Mean', 'Mixed_Yellow_S_Mean', 'Mixed_Yellow_V_Mean', 'Mixed_Yellow_H_Std', 'Mixed_Yellow_S_Std', 'Mixed_Yellow_V_Std'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m create_interaction_features(df)  \u001b[38;5;66;03m# Add interaction features\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Define X (features) and y (target)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbase_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeight\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Train & Evaluate Models\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/SeniorProject/kale_venv/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/SeniorProject/kale_venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/SeniorProject/kale_venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Mixed_RedGreen_Mean', 'Mixed_RedGreen_Std', 'Mixed_L_Mean', 'Mixed_a_Mean', 'Mixed_b_Mean', 'Mixed_L_Std', 'Mixed_a_Std', 'Mixed_b_Std', 'Mixed_H_Mean', 'Mixed_S_Mean', 'Mixed_V_Mean', 'Mixed_H_Std', 'Mixed_S_Std', 'Mixed_V_Std', 'Mixed_RedGreenYellow_Mean', 'Mixed_RedGreenYellow_Std', 'Mixed_Yellow_L_Mean', 'Mixed_Yellow_a_Mean', 'Mixed_Yellow_b_Mean', 'Mixed_Yellow_L_Std', 'Mixed_Yellow_a_Std', 'Mixed_Yellow_b_Std', 'Mixed_Yellow_H_Mean', 'Mixed_Yellow_S_Mean', 'Mixed_Yellow_V_Mean', 'Mixed_Yellow_H_Std', 'Mixed_Yellow_S_Std', 'Mixed_Yellow_V_Std'] not in index\""
     ]
    }
   ],
   "source": [
    "# ðŸ”¹ Load Data\n",
    "# df = mix_orange(df)  # Apply color mixing\n",
    "# df = mix_yellow(df)\n",
    "df = create_interaction_features(df)  # Add interaction features\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "X = df[sum(base_features.values(), [])]\n",
    "y = df[\"Weight\"]\n",
    "\n",
    "# Train & Evaluate Models\n",
    "train_and_evaluate(X, y, progressive_features(base_features), models, \"../output/train_csv/interact.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kale_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
