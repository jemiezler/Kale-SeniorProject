{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   0%|          | 0/337 [00:00<?, ?image/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 337/337 [18:31<00:00,  3.30s/image]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Color statistics extraction complete! Data saved to resources/color_stats.csv\n"
     ]
    }
   ],
   "source": [
    "# Folder containing images\n",
    "FOLDER_PATH = \"resources/images\"  # Change this to your folder path\n",
    "OUTPUT_FILE = \"resources/color_stats.csv\"\n",
    "\n",
    "# Define color spaces and their channels\n",
    "COLOR_SPACES = {\n",
    "    \"RGB\": (None, [\"R\", \"G\", \"B\"]),\n",
    "    \"LAB\": (cv2.COLOR_BGR2LAB, [\"L\", \"A\", \"B\"]),\n",
    "    \"HSV\": (cv2.COLOR_BGR2HSV, [\"H\", \"S\", \"V\"]),\n",
    "    \"GRAY\": (cv2.COLOR_BGR2GRAY, [\"Gray\"])\n",
    "}\n",
    "\n",
    "def extract_color(image, conversion_code):\n",
    "    \"\"\" Convert image to specified color space and return mean & std per channel. \"\"\"\n",
    "    img = cv2.cvtColor(image, conversion_code) if conversion_code else image\n",
    "    return np.concatenate([np.mean(img, axis=(0, 1)), np.std(img, axis=(0, 1))]).astype(float) if img.ndim == 3 else [np.mean(img), np.std(img)]\n",
    "\n",
    "# Get list of image files\n",
    "image_files = [f for f in os.listdir(FOLDER_PATH) if f.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'tiff'))]\n",
    "\n",
    "# Process images with a progress bar\n",
    "data = []\n",
    "for file_name in tqdm(image_files, desc=\"Processing Images\", unit=\"image\"):\n",
    "    image = cv2.imread(os.path.join(FOLDER_PATH, file_name))\n",
    "    if image is not None:\n",
    "        row = [file_name] + [val for space, (conv, _) in COLOR_SPACES.items() for val in extract_color(image, conv)]\n",
    "        data.append(row)\n",
    "\n",
    "# Generate column names dynamically\n",
    "columns = [\"Filename\"] + [f\"{stat}_{space}_{ch}\" for space, (_, chs) in COLOR_SPACES.items() for stat in [\"Mean\", \"Std\"] for ch in chs]\n",
    "\n",
    "# Save results to CSV\n",
    "pd.DataFrame(data, columns=columns).to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"\\nColor statistics extraction complete! Data saved to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texture Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Textures:   0%|          | 0/337 [00:04<?, ?image/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m glcm_features \u001b[38;5;241m=\u001b[39m extract_glcm_features(image)\n\u001b[1;32m     38\u001b[0m lbp_features \u001b[38;5;241m=\u001b[39m extract_lbp_features(image)\n\u001b[0;32m---> 39\u001b[0m hog_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_hog_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m10\u001b[39m]  \u001b[38;5;66;03m# Reduce HOG feature size for storage\u001b[39;00m\n\u001b[1;32m     41\u001b[0m row \u001b[38;5;241m=\u001b[39m [file_name] \u001b[38;5;241m+\u001b[39m glcm_features \u001b[38;5;241m+\u001b[39m lbp_features\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;241m+\u001b[39m hog_features\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     42\u001b[0m data\u001b[38;5;241m.\u001b[39mappend(row)\n",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m, in \u001b[0;36mextract_hog_features\u001b[0;34m(image_gray)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mextract_hog_features\u001b[39m(image_gray):\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Extracts Histogram of Oriented Gradients (HOG) features.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpixels_per_cell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcells_per_block\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_vector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/Kale-SeniorProject/venv/lib/python3.12/site-packages/skimage/_shared/utils.py:445\u001b[0m, in \u001b[0;36mchannel_as_last_axis.__call__.<locals>.fixed_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m channel_axis \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannel_axis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m channel_axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# TODO: convert scalars to a tuple in anticipation of eventually\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m#       supporting a tuple of channel axes. Right now, only an\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m#       integer or a single-element tuple is supported, though.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(channel_axis):\n",
      "File \u001b[0;32m~/Dev/Kale-SeniorProject/venv/lib/python3.12/site-packages/skimage/feature/_hog.py:225\u001b[0m, in \u001b[0;36mhog\u001b[0;34m(image, orientations, pixels_per_cell, cells_per_block, block_norm, visualize, transform_sqrt, feature_vector, channel_axis)\u001b[0m\n\u001b[1;32m    223\u001b[0m     g_col \u001b[38;5;241m=\u001b[39m g_col_by_ch[rr, cc, idcs_max]\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     g_row, g_col \u001b[38;5;241m=\u001b[39m \u001b[43m_hog_channel_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03mThe third stage aims to produce an encoding that is sensitive to\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03mlocal image content while remaining resistant to small changes in\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03mcell are used to vote into the orientation histogram.\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    242\u001b[0m s_row, s_col \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/Dev/Kale-SeniorProject/venv/lib/python3.12/site-packages/skimage/feature/_hog.py:40\u001b[0m, in \u001b[0;36m_hog_channel_gradient\u001b[0;34m(channel)\u001b[0m\n\u001b[1;32m     38\u001b[0m g_row[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     39\u001b[0m g_row[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :] \u001b[38;5;241m=\u001b[39m channel[\u001b[38;5;241m2\u001b[39m:, :] \u001b[38;5;241m-\u001b[39m channel[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, :]\n\u001b[0;32m---> 40\u001b[0m g_col \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m g_col[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     42\u001b[0m g_col[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern, hog\n",
    "\n",
    "# Folder containing images\n",
    "FOLDER_PATH = \"resources/images\"\n",
    "OUTPUT_FILE = \"resources/texture_stats.csv\"\n",
    "\n",
    "# GLCM Features\n",
    "GLCM_PROPS = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "\n",
    "def extract_glcm_features(image_gray):\n",
    "    \"\"\"Extracts GLCM features from grayscale image.\"\"\"\n",
    "    glcm = graycomatrix(image_gray, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    return [graycoprops(glcm, prop).flatten()[0] for prop in GLCM_PROPS]\n",
    "\n",
    "def extract_lbp_features(image_gray):\n",
    "    \"\"\"Extracts Local Binary Pattern (LBP) histogram features.\"\"\"\n",
    "    lbp = local_binary_pattern(image_gray, P=8, R=1, method=\"uniform\")\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), range=(0, 10))\n",
    "    return hist.astype(float)\n",
    "\n",
    "def extract_hog_features(image_gray):\n",
    "    \"\"\"Extracts Histogram of Oriented Gradients (HOG) features.\"\"\"\n",
    "    return hog(image_gray, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
    "\n",
    "# Process all images in the folder\n",
    "data = []\n",
    "image_files = [f for f in os.listdir(FOLDER_PATH) if f.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'tiff'))]\n",
    "\n",
    "for file_name in tqdm(image_files, desc=\"Extracting Textures\", unit=\"image\"):\n",
    "    image = cv2.imread(os.path.join(FOLDER_PATH, file_name), cv2.IMREAD_GRAYSCALE)\n",
    "    if image is not None:\n",
    "        glcm_features = extract_glcm_features(image)\n",
    "        lbp_features = extract_lbp_features(image)\n",
    "        hog_features = extract_hog_features(image)[:10]  # Reduce HOG feature size for storage\n",
    "\n",
    "        row = [file_name] + glcm_features + lbp_features.tolist() + hog_features.tolist()\n",
    "        data.append(row)\n",
    "\n",
    "# Generate column names dynamically\n",
    "columns = [\"Filename\"] + [f\"GLCM_{prop}\" for prop in GLCM_PROPS] + [f\"LBP_{i}\" for i in range(10)] + [f\"HOG_{i}\" for i in range(10)]\n",
    "\n",
    "# Save to CSV\n",
    "pd.DataFrame(data, columns=columns).to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"\\nTexture extraction complete! Data saved to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Color Stat and Weight Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
