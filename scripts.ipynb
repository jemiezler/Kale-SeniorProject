{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Picture Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing images\n",
    "FOLDER_PATH = \"resources/images\"  # Change this to your folder path\n",
    "OUTPUT_FILE = \"resources/color_data.csv\"\n",
    "\n",
    "# Define color spaces and their channels\n",
    "COLOR_SPACES = {\n",
    "    \"RGB\": (None, [\"R\", \"G\", \"B\"]),\n",
    "    \"LAB\": (cv2.COLOR_BGR2LAB, [\"L\", \"A\", \"B\"]),\n",
    "    \"HSV\": (cv2.COLOR_BGR2HSV, [\"H\", \"S\", \"V\"]),\n",
    "    \"GRAY\": (cv2.COLOR_BGR2GRAY, [\"Gray\"])\n",
    "}\n",
    "\n",
    "def extract_color(image, conversion_code):\n",
    "    \"\"\"Convert image to specified color space and return mean & std per channel.\"\"\"\n",
    "    img = cv2.cvtColor(image, conversion_code) if conversion_code else image\n",
    "    # If the image has 3 dimensions (RGB, LAB, HSV), calculate mean and std for each channel\n",
    "    if img.ndim == 3:\n",
    "        return np.concatenate([np.mean(img, axis=(0, 1)), np.std(img, axis=(0, 1))]).astype(float)\n",
    "    # If the image has only 1 channel (GRAY), return mean and std for the grayscale channel\n",
    "    else:\n",
    "        return [np.mean(img), np.std(img)]\n",
    "\n",
    "# Get list of image files\n",
    "image_files = [f for f in os.listdir(FOLDER_PATH) if f.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'tiff'))]\n",
    "\n",
    "# Process images with a progress bar\n",
    "data = []\n",
    "for file_name in tqdm(image_files, desc=\"Processing Images\", unit=\"image\"):\n",
    "    image = cv2.imread(os.path.join(FOLDER_PATH, file_name))\n",
    "    if image is not None:\n",
    "        row = [file_name] + [val for space, (conv, _) in COLOR_SPACES.itempps() for val in extract_color(image, conv)]\n",
    "        data.append(row)\n",
    "\n",
    "# Generate column names dynamically\n",
    "columns = [\"Filename\"] + [f\"{stat}_{space}_{ch}\" for space, (_, chs) in COLOR_SPACES.items() for stat in [\"Mean\", \"Std\"] for ch in chs]\n",
    "\n",
    "# Save results to CSV\n",
    "pd.DataFrame(data, columns=columns).to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"\\nColor statistics extraction complete! Data saved to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texture Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern, hog\n",
    "\n",
    "# Folder containing images\n",
    "FOLDER_PATH = \"resources/images\"\n",
    "OUTPUT_FILE = \"resources/texture_data.csv\"\n",
    "\n",
    "# GLCM Features\n",
    "GLCM_PROPS = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "\n",
    "def extract_glcm_features(image_gray):\n",
    "    \"\"\"Extracts GLCM features from grayscale image.\"\"\"\n",
    "    glcm = graycomatrix(image_gray, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    return [graycoprops(glcm, prop).flatten()[0] for prop in GLCM_PROPS]\n",
    "\n",
    "def extract_lbp_features(image_gray):\n",
    "    \"\"\"Extracts Local Binary Pattern (LBP) histogram features.\"\"\"\n",
    "    lbp = local_binary_pattern(image_gray, P=8, R=1, method=\"uniform\")\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), range=(0, 10))\n",
    "    return hist.astype(float)\n",
    "\n",
    "def extract_hog_features(image_gray):\n",
    "    \"\"\"Extracts Histogram of Oriented Gradients (HOG) features.\"\"\"\n",
    "    return hog(image_gray, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
    "\n",
    "# Process all images in the folder\n",
    "data = []\n",
    "image_files = [f for f in os.listdir(FOLDER_PATH) if f.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'tiff'))]\n",
    "\n",
    "for file_name in tqdm(image_files, desc=\"Extracting Textures\", unit=\"image\"):\n",
    "    image = cv2.imread(os.path.join(FOLDER_PATH, file_name), cv2.IMREAD_GRAYSCALE)\n",
    "    if image is not None:\n",
    "        glcm_features = extract_glcm_features(image)\n",
    "        lbp_features = extract_lbp_features(image)\n",
    "        hog_features = extract_hog_features(image)[:10]  # Reduce HOG feature size for storage\n",
    "\n",
    "        row = [file_name] + glcm_features + lbp_features.tolist() + hog_features.tolist()\n",
    "        data.append(row)\n",
    "\n",
    "# Generate column names dynamically\n",
    "columns = [\"Filename\"] + [f\"GLCM_{prop}\" for prop in GLCM_PROPS] + [f\"LBP_{i}\" for i in range(10)] + [f\"HOG_{i}\" for i in range(10)]\n",
    "\n",
    "# Save to CSV\n",
    "pd.DataFrame(data, columns=columns).to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"\\nTexture extraction complete! Data saved to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_color = pd.read_csv('resources/color_data.csv')\n",
    "df_texture = pd.read_csv('resources/texture_data.csv')\n",
    "df_weight = pd.read_csv('resources/weight_loss_data.csv')\n",
    "df_color.sort_values(by='Filename', inplace=True, ignore_index=True)\n",
    "df_texture.sort_values(by='Filename', inplace=True, ignore_index=True)\n",
    "df_weight.sort_values(by='Filename', inplace=True, ignore_index=True)\n",
    "df = pd.merge(df_weight, df_color, on='Filename')\n",
    "df = pd.merge(df, df_texture, on='Filename')\n",
    "\n",
    "    \n",
    "df[['Day', 'Temp', 'Rep']] = df['Filename'].str.extract(r'(\\d+)_(\\d+)_(\\d+)')\n",
    "df[['Day', 'Temp', 'Rep']] = df[['Day', 'Temp', 'Rep']].astype(float).astype('Int64')\n",
    "df[\"Yellow\"] = ((df[\"Mean_RGB_R\"] + df[\"Mean_RGB_G\"]) - df[\"Mean_RGB_B\"]) / 2\n",
    "df[\"Cyan\"] = ((df[\"Mean_RGB_G\"] + df[\"Mean_RGB_B\"]) - df[\"Mean_RGB_R\"]) / 2\n",
    "df[\"Magenta\"] = df[\"Mean_RGB_R\"] + df[\"Mean_RGB_B\"]\n",
    "df[\"Brightness\"] = (df[\"Mean_RGB_R\"] + df[\"Mean_RGB_G\"] + df[\"Mean_RGB_B\"]) / 3\n",
    "df[\"Chroma\"] = df[[\"Mean_RGB_R\", \"Mean_RGB_G\", \"Mean_RGB_B\"]].max(axis=1) - df[[\"Mean_RGB_R\", \"Mean_RGB_G\", \"Mean_RGB_B\"]].min(axis=1)\n",
    "\n",
    "df.to_csv('resources/combined_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Filename', 'Weight', '%_Weight_Loss', 'Mean_RGB_R', 'Mean_RGB_G',\n",
       "       'Mean_RGB_B', 'Std_RGB_R', 'Std_RGB_G', 'Std_RGB_B', 'Mean_LAB_L',\n",
       "       'Mean_LAB_A', 'Mean_LAB_B', 'Std_LAB_L', 'Std_LAB_A', 'Std_LAB_B',\n",
       "       'Mean_HSV_H', 'Mean_HSV_S', 'Mean_HSV_V', 'Std_HSV_H', 'Std_HSV_S',\n",
       "       'Std_HSV_V', 'Mean_GRAY_Gray', 'Std_GRAY_Gray', 'GLCM_contrast',\n",
       "       'GLCM_dissimilarity', 'GLCM_homogeneity', 'GLCM_energy',\n",
       "       'GLCM_correlation', 'GLCM_ASM', 'LBP_0', 'LBP_1', 'LBP_2', 'LBP_3',\n",
       "       'LBP_4', 'LBP_5', 'LBP_6', 'LBP_7', 'LBP_8', 'LBP_9', 'Day', 'Temp',\n",
       "       'Rep', 'Yellow', 'Cyan', 'Magenta', 'Brightness', 'Chroma'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 1) Define your feature groups\n",
    "# ======================\n",
    "features = {\n",
    "    \"RGB\": [\n",
    "        \"Mean_RGB_R\", \"Std_RGB_R\", \"Mean_RGB_G\", \"Std_RGB_G\", \"Mean_RGB_B\", \"Std_RGB_B\"\n",
    "    ],\n",
    "    \"Lab\": [\n",
    "        \"Mean_LAB_L\", \"Std_LAB_L\", \"Mean_LAB_A\", \"Std_LAB_A\", \"Mean_LAB_B\", \"Std_LAB_B\"\n",
    "    ],\n",
    "    \"HSV\": [\n",
    "        \"Mean_HSV_H\", \"Std_HSV_H\", \"Mean_HSV_S\", \"Std_HSV_S\", \"Mean_HSV_V\", \"Std_HSV_V\"\n",
    "    ],\n",
    "    \"GRAY\": [\n",
    "        \"Mean_GRAY_Gray\", \"Std_GRAY_Gray\"\n",
    "    ],\n",
    "    \"GLCM\": [\n",
    "        \"GLCM_contrast\", \"GLCM_dissimilarity\", \"GLCM_homogeneity\", \n",
    "        \"GLCM_energy\", \"GLCM_correlation\"\n",
    "    ],\n",
    "    \"LBP\": [\n",
    "        \"LBP_0\", \"LBP_1\", \"LBP_2\", \"LBP_3\", \"LBP_4\", \"LBP_5\", \"LBP_6\", \"LBP_7\", \"LBP_8\", \"LBP_9\"\n",
    "    ],\n",
    "    \"Temp\": [\"Temp\"],\n",
    "    \"Yellow\": [\"Yellow\"],\n",
    "    \"Cyan\": [\"Cyan\"],\n",
    "    \"Magenta\": [\"Magenta\"],\n",
    "    \"Brightness\": [\"Brightness\"],\n",
    "    \"Chroma\": [\"Chroma\"],\n",
    "    \"Day\": [\"Day\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Function for Process Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def color_extractor(image_path):\n",
    "    \"\"\"Extract mean and std color statistics for a single image and return as a dictionary with name tags.\"\"\"\n",
    "\n",
    "    # Define color spaces and their channels\n",
    "    COLOR_SPACES = {\n",
    "        \"RGB\": (None, [\"R\", \"G\", \"B\"]),\n",
    "        \"LAB\": (cv2.COLOR_BGR2LAB, [\"L\", \"A\", \"B\"]),\n",
    "        \"HSV\": (cv2.COLOR_BGR2HSV, [\"H\", \"S\", \"V\"]),\n",
    "        \"GRAY\": (cv2.COLOR_BGR2GRAY, [\"Gray\"])\n",
    "    }\n",
    "\n",
    "    def extract_color(image, conversion_code):\n",
    "        \"\"\"Convert image to specified color space and return mean & std per channel.\"\"\"\n",
    "        img = cv2.cvtColor(image, conversion_code) if conversion_code else image\n",
    "        # If the image has 3 dimensions (RGB, LAB, HSV), calculate mean and std for each channel\n",
    "        if img.ndim == 3:\n",
    "            return np.concatenate([np.mean(img, axis=(0, 1)), np.std(img, axis=(0, 1))]).astype(float)\n",
    "        # If the image has only 1 channel (GRAY), return mean and std for the grayscale channel\n",
    "        else:\n",
    "            return [np.mean(img), np.std(img)]\n",
    "\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Image at {image_path} could not be loaded.\")\n",
    "\n",
    "    # Initialize the dictionary to store results with name tags\n",
    "    color_stats_dict = {}\n",
    "\n",
    "    # Extract color statistics for each color space\n",
    "    rgb_means = None\n",
    "    for space, (conv, channels) in COLOR_SPACES.items():\n",
    "        stats = extract_color(image, conv)\n",
    "        for i, channel in enumerate(channels):\n",
    "            color_stats_dict[f\"Mean_{space}_{channel}\"] = float(stats[i])  # Convert to float\n",
    "            color_stats_dict[f\"Std_{space}_{channel}\"] = float(stats[i + len(channels)])  # Convert to float\n",
    "            if space == \"RGB\" and channel == \"B\":  # Make sure we capture RGB values\n",
    "                rgb_means = stats[:3]  # Store the RGB means (R, G, B)\n",
    "\n",
    "    # If RGB means are available, calculate the additional color features\n",
    "    if rgb_means is not None:\n",
    "        R, G, B = rgb_means\n",
    "        # Compute additional color features and ensure they are float\n",
    "        color_stats_dict[\"Yellow\"] = float((R + G - B) / 2)\n",
    "        color_stats_dict[\"Cyan\"] = float((G + B - R) / 2)\n",
    "        color_stats_dict[\"Magenta\"] = float(R + B)\n",
    "        color_stats_dict[\"Brightness\"] = float((R + G + B) / 3)\n",
    "        color_stats_dict[\"Chroma\"] = float(max(R, G, B) - min(R, G, B))\n",
    "\n",
    "    return color_stats_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern, hog\n",
    "\n",
    "# GLCM Features\n",
    "GLCM_PROPS = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "\n",
    "def extract_glcm_features(image_gray):\n",
    "    \"\"\"Extracts GLCM features from grayscale image.\"\"\"\n",
    "    glcm = graycomatrix(image_gray, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    return {f\"GLCM_{prop}\": float(graycoprops(glcm, prop).flatten()[0]) for prop in GLCM_PROPS}  # Convert np.float64 to float\n",
    "\n",
    "def extract_lbp_features(image_gray):\n",
    "    \"\"\"Extracts Local Binary Pattern (LBP) histogram features.\"\"\"\n",
    "    lbp = local_binary_pattern(image_gray, P=8, R=1, method=\"uniform\")\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), range=(0, 10))\n",
    "    return {f\"LBP_{i}\": float(hist[i]) for i in range(10)}  # Convert all LBP values to float\n",
    "\n",
    "def texture_extractor(image_path):\n",
    "    \"\"\"Extract texture features from a single image and return as a dictionary with labels and values.\"\"\"\n",
    "    \n",
    "    # Read the image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Image at {image_path} could not be loaded.\")\n",
    "\n",
    "    # Extract texture features\n",
    "    glcm_features = extract_glcm_features(image)\n",
    "    lbp_features = extract_lbp_features(image)\n",
    "\n",
    "    # Combine features into a single dictionary\n",
    "    texture_features = {**glcm_features, **lbp_features}\n",
    "\n",
    "    return texture_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWithFeatures:\n",
    "    def __init__(self, model, scaler, feature_names):\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        self.model.fit(X_scaled, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict(X_scaled)\n",
    "\n",
    "    def save(self, filepath):\n",
    "        # Save the model, scaler, and feature names\n",
    "        joblib.dump(self, filepath)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filepath):\n",
    "        return joblib.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m r2_train \u001b[38;5;241m=\u001b[39m model_with_features\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mscore(scaler\u001b[38;5;241m.\u001b[39mtransform(X_train_comb), y_train)\n\u001b[1;32m     37\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m model_with_features\u001b[38;5;241m.\u001b[39mpredict(X_test_comb)\n\u001b[0;32m---> 38\u001b[0m r2_test \u001b[38;5;241m=\u001b[39m \u001b[43mr2_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m mse_test \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred_test)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Record performance metrics\u001b[39;00m\n",
      "File \u001b[0;32m~/Dev/Kale-SeniorProject/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/Dev/Kale-SeniorProject/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:1257\u001b[0m, in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \n\u001b[1;32m   1135\u001b[0m \u001b[38;5;124;03mBest possible score is 1.0 and it can be negative (because the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;124;03m-inf\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1252\u001b[0m xp, _, device_ \u001b[38;5;241m=\u001b[39m get_namespace_and_device(\n\u001b[1;32m   1253\u001b[0m     y_true, y_pred, sample_weight, multioutput\n\u001b[1;32m   1254\u001b[0m )\n\u001b[1;32m   1256\u001b[0m _, y_true, y_pred, sample_weight, multioutput \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1257\u001b[0m     \u001b[43m_check_reg_targets_with_floating_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1260\u001b[0m )\n\u001b[1;32m   1262\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y_pred) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/Dev/Kale-SeniorProject/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:198\u001b[0m, in \u001b[0;36m_check_reg_targets_with_floating_dtype\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Ensures that y_true, y_pred, and sample_weight correspond to the same\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mregression task.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    196\u001b[0m dtype_name \u001b[38;5;241m=\u001b[39m _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m--> 198\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# _check_reg_targets does not accept sample_weight as input.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# Convert sample_weight's data type separately to match dtype_name.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Dev/Kale-SeniorProject/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:105\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[1;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m    104\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m--> 105\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Dev/Kale-SeniorProject/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/Dev/Kale-SeniorProject/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:108\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput contains NaN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# We need only consider float arrays, hence can early return for all else.\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreal floating\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomplex floating\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# error message.\u001b[39;00m\n",
      "File \u001b[0;32m~/Dev/Kale-SeniorProject/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:443\u001b[0m, in \u001b[0;36m_NumPyAPIWrapper.isdtype\u001b[0;34m(self, dtype, kind)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21misdtype\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype, kind):\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43misdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;66;03m# In older versions of numpy, data types that arise from outside\u001b[39;00m\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# numpy like from a Polars Series raise a TypeError.\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# e.g. TypeError: Cannot interpret 'Int64' as a data type.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;66;03m# Therefore, we return False.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;66;03m# TODO: Remove when minimum supported version of numpy is >= 1.21.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Dev/Kale-SeniorProject/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:232\u001b[0m, in \u001b[0;36misdtype\u001b[0;34m(dtype, kind, xp)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a boolean indicating whether a provided dtype is of type \"kind\".\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03mIncluded in the v2022.12 of the Array API spec.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03mhttps://data-apis.org/array-api/latest/API_specification/generated/array_api.isdtype.html\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(kind, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_isdtype_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _isdtype_single(dtype, kind, xp\u001b[38;5;241m=\u001b[39mxp)\n",
      "File \u001b[0;32m~/Dev/Kale-SeniorProject/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:232\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a boolean indicating whether a provided dtype is of type \"kind\".\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03mIncluded in the v2022.12 of the Array API spec.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03mhttps://data-apis.org/array-api/latest/API_specification/generated/array_api.isdtype.html\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(kind, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[43m_isdtype_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kind)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _isdtype_single(dtype, kind, xp\u001b[38;5;241m=\u001b[39mxp)\n",
      "File \u001b[0;32m~/Dev/Kale-SeniorProject/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:251\u001b[0m, in \u001b[0;36m_isdtype_single\u001b[0;34m(dtype, kind, xp)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    247\u001b[0m         _isdtype_single(dtype, k, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigned integer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsigned integer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    249\u001b[0m     )\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal floating\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m \u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplex floating\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;66;03m# Some name spaces might not have support for complex dtypes.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     complex_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Dev/Kale-SeniorProject/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:281\u001b[0m, in \u001b[0;36msupported_float_dtypes\u001b[0;34m(xp)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Supported floating point types for the namespace.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03mNote: float16 is not officially part of the Array API spec at the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03mhttps://data-apis.org/array-api/latest/API_specification/data_types.html\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(xp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat16\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m, xp\u001b[38;5;241m.\u001b[39mfloat32, xp\u001b[38;5;241m.\u001b[39mfloat16)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (xp\u001b[38;5;241m.\u001b[39mfloat64, xp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/Dev/Kale-SeniorProject/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:382\u001b[0m, in \u001b[0;36m_NumPyAPIWrapper.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m--> 382\u001b[0m     attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# Support device kwargs and make sure they are on the CPU\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_CREATION_FUNCS:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import joblib\n",
    "from tqdm import tqdm  # Import tqdm for progress bars\n",
    "\n",
    "# Assuming ModelWithFeatures is defined as before\n",
    "\n",
    "# Initialize the model and scaler\n",
    "model = LinearRegression()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Prepare the DataFrame for training (this assumes you have a DataFrame 'df')\n",
    "selected_cols = []\n",
    "for group in features.values():\n",
    "    selected_cols += group\n",
    "\n",
    "X = df[selected_cols]\n",
    "y = df[\"%_Weight_Loss\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a list to collect performance records\n",
    "performance_records = []\n",
    "\n",
    "best_model = None\n",
    "best_score = -float('inf')  # Start with the lowest possible score\n",
    "\n",
    "# Generate feature combinations\n",
    "for r in tqdm(range(2, len(selected_cols) + 1), desc=\"Feature Combinations\", unit=\"group\"):  # Track outer loop progress\n",
    "    for combination in tqdm(itertools.combinations(selected_cols, r), desc=\"Training Models\", unit=\"model\", leave=False):  # Track inner loop progress\n",
    "        # Select the features for this combination\n",
    "        X_train_comb = X_train[list(combination)]\n",
    "        X_test_comb = X_test[list(combination)]\n",
    "\n",
    "        # Initialize the custom model with the selected combination of features\n",
    "        model_with_features = ModelWithFeatures(model, scaler, list(combination))\n",
    "\n",
    "        # Train the model\n",
    "        model_with_features.fit(X_train_comb, y_train)\n",
    "\n",
    "        # Calculate the R^2 score and MSE for the training and test sets\n",
    "        r2_train = model_with_features.model.score(scaler.transform(X_train_comb), y_train)\n",
    "        y_pred_test = model_with_features.predict(X_test_comb)\n",
    "        r2_test = r2_score(y_test, y_pred_test)\n",
    "        mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "        # Record performance metrics\n",
    "        performance_records.append({\n",
    "            'Feature Combination': combination,\n",
    "            'R2_Train': r2_train,\n",
    "            'R2_Test': r2_test,\n",
    "            'MSE_Test': mse_test\n",
    "        })\n",
    "\n",
    "        # Save the best model based on R2_Test (you can also use MSE_Test or other metrics)\n",
    "        if r2_test > best_score:\n",
    "            best_score = r2_test\n",
    "            best_model = model_with_features\n",
    "\n",
    "# Save the performance metrics to a CSV file\n",
    "performance_df = pd.DataFrame(performance_records)\n",
    "performance_df.to_csv('model_performance.csv', index=False)\n",
    "\n",
    "# Save the best performing model\n",
    "if best_model:\n",
    "    best_model.save('output/best_model.pkl')\n",
    "    print(\"Best model saved to 'output/best_model.pkl'\")\n",
    "else:\n",
    "    print(\"No model was trained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names used: ['Mean_RGB_R', 'Std_RGB_R', 'Mean_RGB_G', 'Std_RGB_G', 'Mean_RGB_B', 'Std_RGB_B', 'Mean_LAB_L', 'Std_LAB_L', 'Mean_LAB_A', 'Std_LAB_A', 'Mean_LAB_B', 'Std_LAB_B', 'Mean_HSV_H', 'Std_HSV_H', 'Mean_HSV_S', 'Std_HSV_S', 'Mean_HSV_V', 'Std_HSV_V', 'Mean_GRAY_Gray', 'Std_GRAY_Gray', 'GLCM_contrast', 'GLCM_dissimilarity', 'GLCM_homogeneity', 'GLCM_energy', 'GLCM_correlation', 'LBP_0', 'LBP_1', 'LBP_2', 'LBP_3', 'LBP_4', 'LBP_5', 'LBP_6', 'LBP_7', 'LBP_8', 'LBP_9', 'Temp', 'Yellow', 'Cyan', 'Magenta', 'Brightness', 'Chroma', 'Day']\n",
      "{'Mean_RGB_R': 197.63762544598035, 'Std_RGB_R': 72.37631332056615, 'Mean_RGB_G': 209.1521779640885, 'Std_RGB_G': 52.2815443680636, 'Mean_RGB_B': 204.96656839411216, 'Std_RGB_B': 59.52331688780798, 'Mean_LAB_L': 211.24206311854562, 'Std_LAB_L': 52.17639228085439, 'Mean_LAB_A': 124.40548768735657, 'Std_LAB_A': 7.3633681196553455, 'Mean_LAB_B': 133.7470580984653, 'Std_LAB_B': 12.262759959173898, 'Mean_HSV_H': 50.377384370069564, 'Std_HSV_H': 55.24777561809316, 'Mean_HSV_S': 26.771953662865748, 'Std_HSV_S': 51.623198702150475, 'Mean_HSV_V': 209.88857315422405, 'Std_HSV_V': 52.38797213100764, 'Mean_GRAY_Gray': 206.5764447298121, 'Std_GRAY_Gray': 56.531852008036616, 'Yellow': 100.91161750797836, 'Cyan': 108.24056045611016, 'Magenta': 402.60419384009253, 'Brightness': 203.91879060139368, 'Chroma': 11.514552518108161, 'GLCM_contrast': 27.928156159212374, 'GLCM_dissimilarity': 1.800941837631362, 'GLCM_homogeneity': 0.6779457129401885, 'GLCM_energy': 0.3581718393771594, 'GLCM_correlation': 0.9956542055843305, 'GLCM_ASM': 0.12828706652281768, 'LBP_0': 452916.0, 'LBP_1': 863278.0, 'LBP_2': 359750.0, 'LBP_3': 1109475.0, 'LBP_4': 1140688.0, 'LBP_5': 1590486.0, 'LBP_6': 943676.0, 'LBP_7': 1086815.0, 'LBP_8': 8613398.0, 'LBP_9': 1687838.0, 'Temp': 20, 'Day': 0}\n"
     ]
    }
   ],
   "source": [
    "loaded_model = ModelWithFeatures.load('output/model.pkl')\n",
    "print(\"Feature names used:\", loaded_model.feature_names)\n",
    "\n",
    "color_data = color_extractor('resources/images/0_20_5.png')\n",
    "texture_data= texture_extractor('resources/images/0_20_5.png')\n",
    "data = {**color_data, **texture_data, \"Temp\": 20, \"Day\": 0}\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mean_RGB_R': 197.63762544598035, 'Std_RGB_R': 72.37631332056615, 'Mean_RGB_G': 209.1521779640885, 'Std_RGB_G': 52.2815443680636, 'Mean_RGB_B': 204.96656839411216, 'Std_RGB_B': 59.52331688780798, 'Mean_LAB_L': 211.24206311854562, 'Std_LAB_L': 52.17639228085439, 'Mean_LAB_A': 124.40548768735657, 'Std_LAB_A': 7.3633681196553455, 'Mean_LAB_B': 133.7470580984653, 'Std_LAB_B': 12.262759959173898, 'Mean_HSV_H': 50.377384370069564, 'Std_HSV_H': 55.24777561809316, 'Mean_HSV_S': 26.771953662865748, 'Std_HSV_S': 51.623198702150475, 'Mean_HSV_V': 209.88857315422405, 'Std_HSV_V': 52.38797213100764, 'Mean_GRAY_Gray': 206.5764447298121, 'Std_GRAY_Gray': 56.531852008036616, 'GLCM_contrast': 27.928156159212374, 'GLCM_dissimilarity': 1.800941837631362, 'GLCM_homogeneity': 0.6779457129401885, 'GLCM_energy': 0.3581718393771594, 'GLCM_correlation': 0.9956542055843305, 'LBP_0': 452916.0, 'LBP_1': 863278.0, 'LBP_2': 359750.0, 'LBP_3': 1109475.0, 'LBP_4': 1140688.0, 'LBP_5': 1590486.0, 'LBP_6': 943676.0, 'LBP_7': 1086815.0, 'LBP_8': 8613398.0, 'LBP_9': 1687838.0, 'Temp': 20, 'Yellow': 100.91161750797836, 'Cyan': 108.24056045611016, 'Magenta': 402.60419384009253, 'Brightness': 203.91879060139368, 'Chroma': 11.514552518108161, 'Day': 0}\n"
     ]
    }
   ],
   "source": [
    "for feature in loaded_model.feature_names:\n",
    "    if feature not in data:\n",
    "        data[feature] = None\n",
    "data = {feature: data.get(feature, None) for feature in loaded_model.feature_names}\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.20768328])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(pd.DataFrame([data]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
