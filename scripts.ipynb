{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Picture Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing images\n",
    "FOLDER_PATH = \"resources/images\"  # Change this to your folder path\n",
    "OUTPUT_FILE = \"resources/color_data.csv\"\n",
    "\n",
    "# Define color spaces and their channels\n",
    "COLOR_SPACES = {\n",
    "    \"RGB\": (None, [\"R\", \"G\", \"B\"]),\n",
    "    \"LAB\": (cv2.COLOR_BGR2LAB, [\"L\", \"A\", \"B\"]),\n",
    "    \"HSV\": (cv2.COLOR_BGR2HSV, [\"H\", \"S\", \"V\"]),\n",
    "    \"GRAY\": (cv2.COLOR_BGR2GRAY, [\"Gray\"])\n",
    "}\n",
    "\n",
    "def extract_color(image, conversion_code):\n",
    "    \"\"\"Convert image to specified color space and return mean & std per channel.\"\"\"\n",
    "    img = cv2.cvtColor(image, conversion_code) if conversion_code else image\n",
    "    # If the image has 3 dimensions (RGB, LAB, HSV), calculate mean and std for each channel\n",
    "    if img.ndim == 3:\n",
    "        return np.concatenate([np.mean(img, axis=(0, 1)), np.std(img, axis=(0, 1))]).astype(float)\n",
    "    # If the image has only 1 channel (GRAY), return mean and std for the grayscale channel\n",
    "    else:\n",
    "        return [np.mean(img), np.std(img)]\n",
    "\n",
    "# Get list of image files\n",
    "image_files = [f for f in os.listdir(FOLDER_PATH) if f.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'tiff'))]\n",
    "\n",
    "# Process images with a progress bar\n",
    "data = []\n",
    "for file_name in tqdm(image_files, desc=\"Processing Images\", unit=\"image\"):\n",
    "    image = cv2.imread(os.path.join(FOLDER_PATH, file_name))\n",
    "    if image is not None:\n",
    "        row = [file_name] + [val for space, (conv, _) in COLOR_SPACES.itempps() for val in extract_color(image, conv)]\n",
    "        data.append(row)\n",
    "\n",
    "# Generate column names dynamically\n",
    "columns = [\"Filename\"] + [f\"{stat}_{space}_{ch}\" for space, (_, chs) in COLOR_SPACES.items() for stat in [\"Mean\", \"Std\"] for ch in chs]\n",
    "\n",
    "# Save results to CSV\n",
    "pd.DataFrame(data, columns=columns).to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"\\nColor statistics extraction complete! Data saved to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texture Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern, hog\n",
    "\n",
    "# Folder containing images\n",
    "FOLDER_PATH = \"resources/images\"\n",
    "OUTPUT_FILE = \"resources/texture_data.csv\"\n",
    "\n",
    "# GLCM Features\n",
    "GLCM_PROPS = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "\n",
    "def extract_glcm_features(image_gray):\n",
    "    \"\"\"Extracts GLCM features from grayscale image.\"\"\"\n",
    "    glcm = graycomatrix(image_gray, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    return [graycoprops(glcm, prop).flatten()[0] for prop in GLCM_PROPS]\n",
    "\n",
    "def extract_lbp_features(image_gray):\n",
    "    \"\"\"Extracts Local Binary Pattern (LBP) histogram features.\"\"\"\n",
    "    lbp = local_binary_pattern(image_gray, P=8, R=1, method=\"uniform\")\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), range=(0, 10))\n",
    "    return hist.astype(float)\n",
    "\n",
    "def extract_hog_features(image_gray):\n",
    "    \"\"\"Extracts Histogram of Oriented Gradients (HOG) features.\"\"\"\n",
    "    return hog(image_gray, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
    "\n",
    "# Process all images in the folder\n",
    "data = []\n",
    "image_files = [f for f in os.listdir(FOLDER_PATH) if f.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'tiff'))]\n",
    "\n",
    "for file_name in tqdm(image_files, desc=\"Extracting Textures\", unit=\"image\"):\n",
    "    image = cv2.imread(os.path.join(FOLDER_PATH, file_name), cv2.IMREAD_GRAYSCALE)\n",
    "    if image is not None:\n",
    "        glcm_features = extract_glcm_features(image)\n",
    "        lbp_features = extract_lbp_features(image)\n",
    "        hog_features = extract_hog_features(image)[:10]  # Reduce HOG feature size for storage\n",
    "\n",
    "        row = [file_name] + glcm_features + lbp_features.tolist() + hog_features.tolist()\n",
    "        data.append(row)\n",
    "\n",
    "# Generate column names dynamically\n",
    "columns = [\"Filename\"] + [f\"GLCM_{prop}\" for prop in GLCM_PROPS] + [f\"LBP_{i}\" for i in range(10)] + [f\"HOG_{i}\" for i in range(10)]\n",
    "\n",
    "# Save to CSV\n",
    "pd.DataFrame(data, columns=columns).to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"\\nTexture extraction complete! Data saved to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_color = pd.read_csv('resources/color_data.csv')\n",
    "df_texture = pd.read_csv('resources/texture_data.csv')\n",
    "df_weight = pd.read_csv('resources/weight_loss_data.csv')\n",
    "df_color.sort_values(by='Filename', inplace=True, ignore_index=True)\n",
    "df_texture.sort_values(by='Filename', inplace=True, ignore_index=True)\n",
    "df_weight.sort_values(by='Filename', inplace=True, ignore_index=True)\n",
    "df = pd.merge(df_weight, df_color, on='Filename')\n",
    "df = pd.merge(df, df_texture, on='Filename')\n",
    "\n",
    "    \n",
    "df[['Day', 'Temp', 'Rep']] = df['Filename'].str.extract(r'(\\d+)_(\\d+)_(\\d+)')\n",
    "df[['Day', 'Temp', 'Rep']] = df[['Day', 'Temp', 'Rep']].astype(float).astype('Int64')\n",
    "df[\"Yellow\"] = ((df[\"Mean_RGB_R\"] + df[\"Mean_RGB_G\"]) - df[\"Mean_RGB_B\"]) / 2\n",
    "df[\"Cyan\"] = ((df[\"Mean_RGB_G\"] + df[\"Mean_RGB_B\"]) - df[\"Mean_RGB_R\"]) / 2\n",
    "df[\"Magenta\"] = df[\"Mean_RGB_R\"] + df[\"Mean_RGB_B\"]\n",
    "df[\"Brightness\"] = (df[\"Mean_RGB_R\"] + df[\"Mean_RGB_G\"] + df[\"Mean_RGB_B\"]) / 3\n",
    "df[\"Chroma\"] = df[[\"Mean_RGB_R\", \"Mean_RGB_G\", \"Mean_RGB_B\"]].max(axis=1) - df[[\"Mean_RGB_R\", \"Mean_RGB_G\", \"Mean_RGB_B\"]].min(axis=1)\n",
    "\n",
    "df.to_csv('resources/combined_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Filename', 'Weight', '%_Weight_Loss', 'Mean_RGB_R', 'Mean_RGB_G',\n",
       "       'Mean_RGB_B', 'Std_RGB_R', 'Std_RGB_G', 'Std_RGB_B', 'Mean_LAB_L',\n",
       "       'Mean_LAB_A', 'Mean_LAB_B', 'Std_LAB_L', 'Std_LAB_A', 'Std_LAB_B',\n",
       "       'Mean_HSV_H', 'Mean_HSV_S', 'Mean_HSV_V', 'Std_HSV_H', 'Std_HSV_S',\n",
       "       'Std_HSV_V', 'Mean_GRAY_Gray', 'Std_GRAY_Gray', 'GLCM_contrast',\n",
       "       'GLCM_dissimilarity', 'GLCM_homogeneity', 'GLCM_energy',\n",
       "       'GLCM_correlation', 'GLCM_ASM', 'LBP_0', 'LBP_1', 'LBP_2', 'LBP_3',\n",
       "       'LBP_4', 'LBP_5', 'LBP_6', 'LBP_7', 'LBP_8', 'LBP_9', 'Day', 'Temp',\n",
       "       'Rep', 'Yellow', 'Cyan', 'Magenta', 'Brightness', 'Chroma'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 1) Define your feature groups\n",
    "# ======================\n",
    "features = {\n",
    "    \"RGB\": [\n",
    "        \"Mean_RGB_R\", \"Std_RGB_R\", \"Mean_RGB_G\", \"Std_RGB_G\", \"Mean_RGB_B\", \"Std_RGB_B\"\n",
    "    ],\n",
    "    \"Lab\": [\n",
    "        \"Mean_LAB_L\", \"Std_LAB_L\", \"Mean_LAB_A\", \"Std_LAB_A\", \"Mean_LAB_B\", \"Std_LAB_B\"\n",
    "    ],\n",
    "    \"HSV\": [\n",
    "        \"Mean_HSV_H\", \"Std_HSV_H\", \"Mean_HSV_S\", \"Std_HSV_S\", \"Mean_HSV_V\", \"Std_HSV_V\"\n",
    "    ],\n",
    "    \"GRAY\": [\n",
    "        \"Mean_GRAY_Gray\", \"Std_GRAY_Gray\"\n",
    "    ],\n",
    "    \"GLCM\": [\n",
    "        \"GLCM_contrast\", \"GLCM_dissimilarity\", \"GLCM_homogeneity\", \n",
    "        \"GLCM_energy\", \"GLCM_correlation\"\n",
    "    ],\n",
    "    \"LBP\": [\n",
    "        \"LBP_0\", \"LBP_1\", \"LBP_2\", \"LBP_3\", \"LBP_4\", \"LBP_5\", \"LBP_6\", \"LBP_7\", \"LBP_8\", \"LBP_9\"\n",
    "    ],\n",
    "    \"Temp\": [\"Temp\"],\n",
    "    \"Yellow\": [\"Yellow\"],\n",
    "    \"Cyan\": [\"Cyan\"],\n",
    "    \"Magenta\": [\"Magenta\"],\n",
    "    \"Brightness\": [\"Brightness\"],\n",
    "    \"Chroma\": [\"Chroma\"],\n",
    "    \"Day\": [\"Day\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Function for Process Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def color_extractor(image_path):\n",
    "    \"\"\"Extract mean and std color statistics for a single image and return as a dictionary with name tags.\"\"\"\n",
    "\n",
    "    # Define color spaces and their channels\n",
    "    COLOR_SPACES = {\n",
    "        \"RGB\": (None, [\"R\", \"G\", \"B\"]),\n",
    "        \"LAB\": (cv2.COLOR_BGR2LAB, [\"L\", \"A\", \"B\"]),\n",
    "        \"HSV\": (cv2.COLOR_BGR2HSV, [\"H\", \"S\", \"V\"]),\n",
    "        \"GRAY\": (cv2.COLOR_BGR2GRAY, [\"Gray\"])\n",
    "    }\n",
    "\n",
    "    def extract_color(image, conversion_code):\n",
    "        \"\"\"Convert image to specified color space and return mean & std per channel.\"\"\"\n",
    "        img = cv2.cvtColor(image, conversion_code) if conversion_code else image\n",
    "        # If the image has 3 dimensions (RGB, LAB, HSV), calculate mean and std for each channel\n",
    "        if img.ndim == 3:\n",
    "            return np.concatenate([np.mean(img, axis=(0, 1)), np.std(img, axis=(0, 1))]).astype(float)\n",
    "        # If the image has only 1 channel (GRAY), return mean and std for the grayscale channel\n",
    "        else:\n",
    "            return [np.mean(img), np.std(img)]\n",
    "\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Image at {image_path} could not be loaded.\")\n",
    "\n",
    "    # Initialize the dictionary to store results with name tags\n",
    "    color_stats_dict = {}\n",
    "\n",
    "    # Extract color statistics for each color space\n",
    "    rgb_means = None\n",
    "    for space, (conv, channels) in COLOR_SPACES.items():\n",
    "        stats = extract_color(image, conv)\n",
    "        for i, channel in enumerate(channels):\n",
    "            color_stats_dict[f\"Mean_{space}_{channel}\"] = float(stats[i])  # Convert to float\n",
    "            color_stats_dict[f\"Std_{space}_{channel}\"] = float(stats[i + len(channels)])  # Convert to float\n",
    "            if space == \"RGB\" and channel == \"B\":  # Make sure we capture RGB values\n",
    "                rgb_means = stats[:3]  # Store the RGB means (R, G, B)\n",
    "\n",
    "    # If RGB means are available, calculate the additional color features\n",
    "    if rgb_means is not None:\n",
    "        R, G, B = rgb_means\n",
    "        # Compute additional color features and ensure they are float\n",
    "        color_stats_dict[\"Yellow\"] = float((R + G - B) / 2)\n",
    "        color_stats_dict[\"Cyan\"] = float((G + B - R) / 2)\n",
    "        color_stats_dict[\"Magenta\"] = float(R + B)\n",
    "        color_stats_dict[\"Brightness\"] = float((R + G + B) / 3)\n",
    "        color_stats_dict[\"Chroma\"] = float(max(R, G, B) - min(R, G, B))\n",
    "\n",
    "    return color_stats_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern, hog\n",
    "\n",
    "# GLCM Features\n",
    "GLCM_PROPS = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "\n",
    "def extract_glcm_features(image_gray):\n",
    "    \"\"\"Extracts GLCM features from grayscale image.\"\"\"\n",
    "    glcm = graycomatrix(image_gray, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    return {f\"GLCM_{prop}\": float(graycoprops(glcm, prop).flatten()[0]) for prop in GLCM_PROPS}  # Convert np.float64 to float\n",
    "\n",
    "def extract_lbp_features(image_gray):\n",
    "    \"\"\"Extracts Local Binary Pattern (LBP) histogram features.\"\"\"\n",
    "    lbp = local_binary_pattern(image_gray, P=8, R=1, method=\"uniform\")\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 11), range=(0, 10))\n",
    "    return {f\"LBP_{i}\": float(hist[i]) for i in range(10)}  # Convert all LBP values to float\n",
    "\n",
    "def texture_extractor(image_path):\n",
    "    \"\"\"Extract texture features from a single image and return as a dictionary with labels and values.\"\"\"\n",
    "    \n",
    "    # Read the image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Image at {image_path} could not be loaded.\")\n",
    "\n",
    "    # Extract texture features\n",
    "    glcm_features = extract_glcm_features(image)\n",
    "    lbp_features = extract_lbp_features(image)\n",
    "\n",
    "    # Combine features into a single dictionary\n",
    "    texture_features = {**glcm_features, **lbp_features}\n",
    "\n",
    "    return texture_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWithFeatures:\n",
    "    def __init__(self, model, scaler, feature_names):\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        self.model.fit(X_scaled, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict(X_scaled)\n",
    "\n",
    "    def save(self, filepath):\n",
    "        # Save the model, scaler, and feature names\n",
    "        joblib.dump(self, filepath)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filepath):\n",
    "        return joblib.load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# เตรียมข้อมูล\u001b[39;00m\n\u001b[1;32m     39\u001b[0m selected_cols \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m group]\n\u001b[0;32m---> 40\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[selected_cols]\n\u001b[1;32m     41\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m_Weight_Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# แบ่งข้อมูล train-test\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# ตั้งค่า logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# สมมติว่า ModelWithFeatures ถูกกำหนดไว้แล้ว\n",
    "# สมมติว่ามี DataFrame ชื่อ df และ column เป้าหมายคือ \"%_Weight_Loss\"\n",
    "\n",
    "# กำหนด feature groups\n",
    "features = {\n",
    "    \"RGB\": [\"Mean_RGB_R\", \"Std_RGB_R\", \"Mean_RGB_G\", \"Std_RGB_G\", \"Mean_RGB_B\", \"Std_RGB_B\"],\n",
    "    \"Lab\": [\"Mean_LAB_L\", \"Std_LAB_L\", \"Mean_LAB_A\", \"Std_LAB_A\", \"Mean_LAB_B\", \"Std_LAB_B\"],\n",
    "    \"HSV\": [\"Mean_HSV_H\", \"Std_HSV_H\", \"Mean_HSV_S\", \"Std_HSV_S\", \"Mean_HSV_V\", \"Std_HSV_V\"],\n",
    "    \"GRAY\": [\"Mean_GRAY_Gray\", \"Std_GRAY_Gray\"],\n",
    "    \"GLCM\": [\"GLCM_contrast\", \"GLCM_dissimilarity\", \"GLCM_homogeneity\", \"GLCM_energy\", \"GLCM_correlation\"],\n",
    "    \"LBP\": [\"LBP_0\", \"LBP_1\", \"LBP_2\", \"LBP_3\", \"LBP_4\", \"LBP_5\", \"LBP_6\", \"LBP_7\", \"LBP_8\", \"LBP_9\"],\n",
    "    \"Temp\": [\"Temp\"],\n",
    "    \"Yellow\": [\"Yellow\"],\n",
    "    \"Cyan\": [\"Cyan\"],\n",
    "    \"Magenta\": [\"Magenta\"],\n",
    "    \"Brightness\": [\"Brightness\"],\n",
    "    \"Chroma\": [\"Chroma\"],\n",
    "    \"Day\": [\"Day\"],\n",
    "}\n",
    "\n",
    "# สร้างรายชื่อกลุ่ม feature\n",
    "feature_groups = list(features.keys())\n",
    "\n",
    "# เตรียมข้อมูล\n",
    "selected_cols = [col for group in features.values() for col in group]\n",
    "X = df[selected_cols]\n",
    "y = df[\"%_Weight_Loss\"]\n",
    "\n",
    "# แบ่งข้อมูล train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# บันทึก performance\n",
    "performance_records = []\n",
    "\n",
    "# ค่าที่ดีที่สุดเริ่มต้น\n",
    "best_model = None\n",
    "best_score = -float('inf')\n",
    "\n",
    "logger.info(\"เริ่มกระบวนการฝึกโมเดลโดยใช้ feature group combinations...\")\n",
    "\n",
    "# วนลูปตามกลุ่ม feature\n",
    "for r in tqdm(range(1, len(feature_groups) + 1), desc=\"Group Combinations\", unit=\"group\"):\n",
    "    for group_combination in tqdm(itertools.combinations(feature_groups, r), desc=\"Training Models\", unit=\"model\", leave=False):\n",
    "        selected_features = [feature for group in group_combination for feature in features[group]]\n",
    "\n",
    "        logger.info(f\"ฝึกโมเดลโดยใช้กลุ่ม feature: {group_combination}\")\n",
    "\n",
    "        # เลือก feature ตามกลุ่มที่กำหนด\n",
    "        X_train_comb = X_train[selected_features]\n",
    "        X_test_comb = X_test[selected_features]\n",
    "\n",
    "        # สร้าง model\n",
    "        model = LinearRegression()\n",
    "        scaler = StandardScaler()\n",
    "        model_with_features = ModelWithFeatures(model, scaler, selected_features)\n",
    "\n",
    "        try:\n",
    "            # Train model\n",
    "            model_with_features.fit(X_train_comb, y_train)\n",
    "\n",
    "            # คำนวณค่า metric\n",
    "            r2_train = model_with_features.model.score(scaler.transform(X_train_comb), y_train)\n",
    "            y_pred_test = model_with_features.predict(X_test_comb)\n",
    "            r2_test = r2_score(y_test, y_pred_test)\n",
    "            mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "            # บันทึกผลลัพธ์\n",
    "            performance_records.append({\n",
    "                'Feature Group': group_combination,\n",
    "                'R2_Train': r2_train,\n",
    "                'R2_Test': r2_test,\n",
    "                'MSE_Test': mse_test\n",
    "            })\n",
    "\n",
    "            logger.info(f\"Model {group_combination} -> R2_Test: {r2_test:.4f}, MSE_Test: {mse_test:.4f}\")\n",
    "\n",
    "            # อัปเดต best model\n",
    "            if r2_test > best_score:\n",
    "                best_score = r2_test\n",
    "                best_model = model_with_features\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"เกิดข้อผิดพลาดในการฝึกโมเดลสำหรับ {group_combination}: {e}\")\n",
    "\n",
    "# บันทึกผลลัพธ์ลงไฟล์ CSV\n",
    "performance_df = pd.DataFrame(performance_records)\n",
    "performance_df.to_csv('model_performance.csv', index=False)\n",
    "\n",
    "# บันทึกโมเดลที่ดีที่สุด\n",
    "if best_model:\n",
    "    best_model.save('output/best_model.pkl')\n",
    "    logger.info(\"บันทึก best model ไปที่ 'output/best_model.pkl' สำเร็จ\")\n",
    "else:\n",
    "    logger.warning(\"ไม่พบโมเดลที่ดีที่สุด\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names used: ['Mean_RGB_R', 'Std_RGB_R', 'Mean_RGB_G', 'Std_RGB_G', 'Mean_RGB_B', 'Std_RGB_B', 'Mean_LAB_L', 'Std_LAB_L', 'Mean_LAB_A', 'Std_LAB_A', 'Mean_LAB_B', 'Std_LAB_B', 'Mean_HSV_H', 'Std_HSV_H', 'Mean_HSV_S', 'Std_HSV_S', 'Mean_HSV_V', 'Std_HSV_V', 'Mean_GRAY_Gray', 'Std_GRAY_Gray', 'GLCM_contrast', 'GLCM_dissimilarity', 'GLCM_homogeneity', 'GLCM_energy', 'GLCM_correlation', 'LBP_0', 'LBP_1', 'LBP_2', 'LBP_3', 'LBP_4', 'LBP_5', 'LBP_6', 'LBP_7', 'LBP_8', 'LBP_9', 'Temp', 'Yellow', 'Cyan', 'Magenta', 'Brightness', 'Chroma', 'Day']\n",
      "{'Mean_RGB_R': 197.63762544598035, 'Std_RGB_R': 72.37631332056615, 'Mean_RGB_G': 209.1521779640885, 'Std_RGB_G': 52.2815443680636, 'Mean_RGB_B': 204.96656839411216, 'Std_RGB_B': 59.52331688780798, 'Mean_LAB_L': 211.24206311854562, 'Std_LAB_L': 52.17639228085439, 'Mean_LAB_A': 124.40548768735657, 'Std_LAB_A': 7.3633681196553455, 'Mean_LAB_B': 133.7470580984653, 'Std_LAB_B': 12.262759959173898, 'Mean_HSV_H': 50.377384370069564, 'Std_HSV_H': 55.24777561809316, 'Mean_HSV_S': 26.771953662865748, 'Std_HSV_S': 51.623198702150475, 'Mean_HSV_V': 209.88857315422405, 'Std_HSV_V': 52.38797213100764, 'Mean_GRAY_Gray': 206.5764447298121, 'Std_GRAY_Gray': 56.531852008036616, 'Yellow': 100.91161750797836, 'Cyan': 108.24056045611016, 'Magenta': 402.60419384009253, 'Brightness': 203.91879060139368, 'Chroma': 11.514552518108161, 'GLCM_contrast': 27.928156159212374, 'GLCM_dissimilarity': 1.800941837631362, 'GLCM_homogeneity': 0.6779457129401885, 'GLCM_energy': 0.3581718393771594, 'GLCM_correlation': 0.9956542055843305, 'GLCM_ASM': 0.12828706652281768, 'LBP_0': 452916.0, 'LBP_1': 863278.0, 'LBP_2': 359750.0, 'LBP_3': 1109475.0, 'LBP_4': 1140688.0, 'LBP_5': 1590486.0, 'LBP_6': 943676.0, 'LBP_7': 1086815.0, 'LBP_8': 8613398.0, 'LBP_9': 1687838.0, 'Temp': 20, 'Day': 0}\n"
     ]
    }
   ],
   "source": [
    "loaded_model = ModelWithFeatures.load('output/model.pkl')\n",
    "print(\"Feature names used:\", loaded_model.feature_names)\n",
    "\n",
    "color_data = color_extractor('resources/images/0_20_5.png')\n",
    "texture_data= texture_extractor('resources/images/0_20_5.png')\n",
    "data = {**color_data, **texture_data, \"Temp\": 20, \"Day\": 0}\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mean_RGB_R': 197.63762544598035, 'Std_RGB_R': 72.37631332056615, 'Mean_RGB_G': 209.1521779640885, 'Std_RGB_G': 52.2815443680636, 'Mean_RGB_B': 204.96656839411216, 'Std_RGB_B': 59.52331688780798, 'Mean_LAB_L': 211.24206311854562, 'Std_LAB_L': 52.17639228085439, 'Mean_LAB_A': 124.40548768735657, 'Std_LAB_A': 7.3633681196553455, 'Mean_LAB_B': 133.7470580984653, 'Std_LAB_B': 12.262759959173898, 'Mean_HSV_H': 50.377384370069564, 'Std_HSV_H': 55.24777561809316, 'Mean_HSV_S': 26.771953662865748, 'Std_HSV_S': 51.623198702150475, 'Mean_HSV_V': 209.88857315422405, 'Std_HSV_V': 52.38797213100764, 'Mean_GRAY_Gray': 206.5764447298121, 'Std_GRAY_Gray': 56.531852008036616, 'GLCM_contrast': 27.928156159212374, 'GLCM_dissimilarity': 1.800941837631362, 'GLCM_homogeneity': 0.6779457129401885, 'GLCM_energy': 0.3581718393771594, 'GLCM_correlation': 0.9956542055843305, 'LBP_0': 452916.0, 'LBP_1': 863278.0, 'LBP_2': 359750.0, 'LBP_3': 1109475.0, 'LBP_4': 1140688.0, 'LBP_5': 1590486.0, 'LBP_6': 943676.0, 'LBP_7': 1086815.0, 'LBP_8': 8613398.0, 'LBP_9': 1687838.0, 'Temp': 20, 'Yellow': 100.91161750797836, 'Cyan': 108.24056045611016, 'Magenta': 402.60419384009253, 'Brightness': 203.91879060139368, 'Chroma': 11.514552518108161, 'Day': 0}\n"
     ]
    }
   ],
   "source": [
    "for feature in loaded_model.feature_names:\n",
    "    if feature not in data:\n",
    "        data[feature] = None\n",
    "data = {feature: data.get(feature, None) for feature in loaded_model.feature_names}\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.20768328])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(pd.DataFrame([data]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
